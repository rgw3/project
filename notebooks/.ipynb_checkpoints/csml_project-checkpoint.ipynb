{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "3cd85129-5d96-4c39-8599-8a39bcf1f022",
   "metadata": {},
   "source": [
    "# Notebook Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6f184f7-35e4-4e59-91e6-9b91bf39b2fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# clear old data this can be deleted when published, for using when Kernel must restart\n",
    "import os\n",
    "import shutil\n",
    "\n",
    "# Construct the path relative to the notebook location\n",
    "data_dir = os.path.join(os.path.dirname(os.getcwd()), 'data', 'raw')\n",
    "\n",
    "# Confirm the path\n",
    "print(f\"Target directory: {data_dir}\")\n",
    "\n",
    "# Check if the directory exists\n",
    "if os.path.exists(data_dir):\n",
    "    # Iterate through everything in the folder\n",
    "    for filename in os.listdir(data_dir):\n",
    "        file_path = os.path.join(data_dir, filename)\n",
    "        try:\n",
    "            # Remove files and directories\n",
    "            if os.path.isfile(file_path) or os.path.islink(file_path):\n",
    "                os.remove(file_path)\n",
    "            elif os.path.isdir(file_path):\n",
    "                shutil.rmtree(file_path)\n",
    "        except Exception as e:\n",
    "            print(f\"Failed to delete {file_path}. Reason: {e}\")\n",
    "    print(\"All data in /data/raw has been deleted.\")\n",
    "else:\n",
    "    print(\"The /data/raw directory does not exist.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad285ea9-491c-4897-8668-35e9c33dc5b5",
   "metadata": {},
   "source": [
    "### Import API Keys\n",
    "This imports my API keys, users will need to set up their own API keys in a file called <b><i>project_api_keys.ipynb</i></b> with the following code:<br><br>\n",
    "<b>\n",
    "import os<br>\n",
    "os.environ[\"KAGGLE_USERNAME\"] = \"your_kaggle_user_name\"<br>\n",
    "os.environ[\"KAGGLE_API_KEY\"] = \"your_kaggle_api_key\"<br>\n",
    "os.environ[\"BEA_API_KEY\"] = \"your_bea_api_key\"<br></b>\n",
    "\n",
    "<i>Alternatively, users can simply create their own variables with values without using an alternative file.</i>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8ea69334-d6e4-4a61-be15-cf71459be9b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "%run project_api_keys.ipynb\n",
    "kaggle_username = os.environ.get(\"KAGGLE_USERNAME\")\n",
    "kaggle_api_key = os.environ.get(\"KAGGLE_API_KEY\")\n",
    "bea_api_key = os.environ.get(\"BEA_API_KEY\")\n",
    "\n",
    "os.environ['KAGGLE_USERNAME'] = kaggle_username\n",
    "os.environ['KAGGLE_KEY'] = kaggle_api_key"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6b279910-41a1-4681-9edb-726b4d058ae3",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Installs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "160c370c-84be-45ab-b5b8-0d1a81a1b294",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# installs - assumes only jupyter-lab has been installed\n",
    "!pip3 install -qU pandas kaggle matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3a6975c7-29d1-4999-bcd7-0822b315631d",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15a619ec-ccc8-4f20-be29-75ae19547508",
   "metadata": {},
   "outputs": [],
   "source": [
    "# imports\n",
    "import pandas as pd\n",
    "import requests\n",
    "import os\n",
    "from pathlib import Path\n",
    "import kaggle\n",
    "import matplotlib"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4b3787a-58d8-4d60-91b1-88c35d63a546",
   "metadata": {},
   "source": [
    "# Project Name: Post Disaster Economic Recovery Model\n",
    " - Student <b>Name: Robert Williams</b>\n",
    " - UTeid: <b>rgw65</b>\n",
    " - Course: <b>Case Studies in Machine Learning AI391M (54340)</b>\n",
    " - Term: <b>Fall 2025</b>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb4d4de5-71b5-4040-854f-cf1702a262e5",
   "metadata": {},
   "source": [
    "I would like to take a moment to acknowledge <b>[Aurélien Géron](https://www.oreilly.com/pub/au/7106)</b> author of <b>[Hands-On Machine Learning with Scikit-Learn, Keras, and TensorFlow](https://www.oreilly.com/library/view/hands-on-machine-learning/9781098125967/)</b>.\n",
    "The structure of this machine learning project is based upon his Machine Learning Project Checklist (Appendix A). It has been an invaluable resource."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17c8109e-5f14-4bd8-b020-75e62769ca54",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 1. Frame the Problem and Look at the Big Picture\n",
    " - Define the objective in business terms.\n",
    " - How will your solution be used?\n",
    " - What are the current solutions/workarounds (if any)?\n",
    " - How should you frame this problem (supervised/unsupervised, online/offline, etc.)?\n",
    " - How should performance be measured?\n",
    " - Is the performance measure aligned with the business objective?\n",
    " - What would be the minimum performance needed to reach the business objective?\n",
    " - What are comparable problems? Can you reuse experience or tools?\n",
    " - Is human expertise available?\n",
    " - How would you solve the problem manually?\n",
    " - List the assumptions you (or others) have made so far.\n",
    " - Verify assumptions if possible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "afefaef2-c058-4966-8532-5cb899826018",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "## 2. Get the Data\n",
    "Note: automate as much as possible so you can easily get fresh data.\n",
    " - List the data you need and how much you need.\n",
    " - Find and document where you can get that data.\n",
    " - Check how much space it will take.\n",
    " - Check legal obligations, and get authorization if necessary.\n",
    " - Get access authorizations.\n",
    " - Create a workspace (with enough storage space).\n",
    " - Get the data.\n",
    " - Convert the data to a format you can easily manipulate (without changing the data itself).\n",
    " - Ensure sensitive information is deleted or protected (e.g., anonymized).\n",
    " - Check the size and type of data (time series, sample, geographical, etc.).\n",
    " - Sample a test set, put it aside, and never look at it (no data snooping!)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a7826ebd-0ac3-42fc-9939-57428513ff12",
   "metadata": {},
   "source": [
    "### Configure folder structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c09a7e63-8688-4172-9d87-7a6b5974fc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set up paths relative to the notebooks folder\n",
    "# When running from notebooks folder, go up one level to project root, then into data/raw\n",
    "NOTEBOOK_DIR = Path.cwd()  # Current working directory (notebooks folder)\n",
    "PROJECT_ROOT = NOTEBOOK_DIR.parent  # Go up to project folder\n",
    "DATA_RAW_DIR = PROJECT_ROOT / \"data\" / \"raw\"\n",
    "\n",
    "# Create the data/raw directory if it doesn't exist\n",
    "DATA_RAW_DIR.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "279a844c-4b0c-42a3-b2fd-2f58da1809c0",
   "metadata": {},
   "source": [
    "### FEMA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c6ba462-e486-41f3-aa8f-cc838647eaba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# FEMA OpenFEMA API endpoint for Disaster Declarations Summaries\n",
    "FEMA_URL = \"https://www.fema.gov/api/open/v2/DisasterDeclarationsSummaries.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58875abf-a364-4ebd-b469-ecfba5632ab1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# File to save the downloaded data\n",
    "FEMA_FILE = DATA_RAW_DIR / \"fema_disaster_declarations.csv\"\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a8eabcae-48e4-4da3-b53f-ee27b75d5cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to download fema data\n",
    "def download_fema_data():\n",
    "    \"\"\"\n",
    "    Download FEMA Disaster Declarations Summaries dataset\n",
    "    \"\"\"\n",
    "    print(\"Downloading FEMA data...\")\n",
    "    print(f\"URL: {FEMA_URL}\")\n",
    "    \n",
    "    try:\n",
    "        # Download the file\n",
    "        response = requests.get(FEMA_URL, timeout=60)\n",
    "        response.raise_for_status()  # Raise an error for bad status codes\n",
    "        \n",
    "        # Save to file\n",
    "        with open(FEMA_FILE, 'wb') as f:\n",
    "            f.write(response.content)\n",
    "        \n",
    "        print(f\"✓ Data downloaded successfully: {FEMA_FILE}\")\n",
    "        print(f\"  File size: {FEMA_FILE.stat().st_size / (1024*1024):.2f} MB\")\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"✗ Error downloading data: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba422eb4-b13c-4ba3-9865-cc24986a4cfe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load fema data to dataframe\n",
    "def load_fema_data():\n",
    "    \"\"\"\n",
    "    Load FEMA data into a pandas DataFrame\n",
    "    \"\"\"\n",
    "    print(\"\\nLoading FEMA data into DataFrame...\")\n",
    "    \n",
    "    try:\n",
    "        # Read CSV into DataFrame\n",
    "        df = pd.read_csv(FEMA_FILE, low_memory=False)\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e6b425f-6871-46c3-a3e8-c12a7e0bf69d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "download_fema_data()\n",
    "# load data into dataframe\n",
    "fema_df = load_fema_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3052252-e96c-48f7-a850-3e2c7b895096",
   "metadata": {},
   "outputs": [],
   "source": [
    "# spot check on data\n",
    "fema_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16f546dd-5f62-40c4-aae4-c906963cb4f6",
   "metadata": {},
   "source": [
    "### NOAA Billion-Dollar Weather and Climate Disasters\n",
    "### This section needs help as it is not pulling the right data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fab77c36-f4b1-4ea6-b071-0b1d2541b421",
   "metadata": {},
   "outputs": [],
   "source": [
    "# NOAA Billion-Dollar Disasters data\n",
    "# Note: This dataset is available on Kaggle\n",
    "# Direct download link from NOAA NCEI\n",
    "NOAA_URL = \"https://www.ncei.noaa.gov/pub/data/billions/events.csv\"\n",
    "NOAA_FILE = DATA_RAW_DIR / \"events-US-1980-2021.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "522c2d07-f286-4b4f-9648-7c342903ab32",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to download NOAA data from Kaggle\n",
    "def download_noaa_data():\n",
    "    \"\"\"\n",
    "    Download NOAA Billion-Dollar Weather and Climate Disasters dataset from Kaggle\n",
    "    Note: Uses KAGGLE_USERNAME and KAGGLE_API_KEY from environment variables\n",
    "    Dataset: https://www.kaggle.com/datasets/noaa/noaa-billion-dollar-weather-and-climate-disasters\n",
    "    \"\"\"\n",
    "    print(\"Downloading NOAA data from Kaggle...\")\n",
    "    \n",
    "    try:\n",
    "        # Kaggle dataset identifier\n",
    "        dataset = \"noaa/noaa-billion-dollar-weather-and-climate-disasters\"\n",
    "        dataset = \"christinezinkand/us-billiondollar-weather-and-climate-disasters\"\n",
    "        \n",
    "        # Download dataset to the raw data directory\n",
    "        kaggle.api.dataset_download_files(\n",
    "            dataset,\n",
    "            path=DATA_RAW_DIR,\n",
    "            unzip=True,\n",
    "            quiet=False\n",
    "        )\n",
    "        \n",
    "        print(f\"✓ Data downloaded successfully to: {DATA_RAW_DIR}\")\n",
    "        \n",
    "        # The main file should be in the directory\n",
    "        # Check what files were downloaded\n",
    "        downloaded_files = list(DATA_RAW_DIR.glob(\"*.csv\"))\n",
    "        print(f\"  Downloaded files: {[f.name for f in downloaded_files]}\")\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error downloading data: {e}\")\n",
    "        print(\"\\nMake sure you have:\")\n",
    "        print(\"1. Valid Kaggle API credentials in your project_api_keys.ipynb\")\n",
    "        print(\"2. Accepted the dataset terms at: https://www.kaggle.com/datasets/noaa/noaa-billion-dollar-weather-and-climate-disasters\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "29ea6bea-99bc-4589-b086-0731ec0ca0bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load NOAA data to dataframe\n",
    "def load_noaa_data():\n",
    "    \"\"\"\n",
    "    Load NOAA data into a pandas DataFrame\n",
    "    \"\"\"\n",
    "    print(\"\\nLoading NOAA data into DataFrame...\")\n",
    "    \n",
    "    try:\n",
    "        # Read CSV into DataFrame\n",
    "        df = pd.read_csv(NOAA_FILE, low_memory=False)\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3faa6d91-89d7-4d3b-b48c-67b7c4fd8c7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# download data\n",
    "download_noaa_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adb4af8a-858d-44f2-baa6-7896022a1b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load into dataframe\n",
    "noaa_df = load_noaa_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f5432bf-dc04-4521-8d12-a42017282296",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# spot check on data\n",
    "noaa_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "078b862a-cbdd-4e4e-b351-9c6297341cb7",
   "metadata": {},
   "source": [
    "### BEA Regional GDP by County"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1dc569be-b40c-461b-84e3-da7d7ee4bc3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# BEA API endpoint for Regional GDP by County\n",
    "BEA_API_URL = \"https://apps.bea.gov/api/data\"\n",
    "BEA_FILE = DATA_RAW_DIR / \"bea_county_gdp.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e36c4a65-dee2-436b-bb12-9581b34e6836",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to download BEA Regional GDP data\n",
    "def download_bea_data():\n",
    "    \"\"\"\n",
    "    Download BEA Regional GDP by County (CAGDP) dataset using BEA API\n",
    "    Note: Uses BEA_API_KEY from environment variables\n",
    "    API Documentation: https://apps.bea.gov/api/\n",
    "    \"\"\"\n",
    "    print(\"Downloading BEA Regional GDP data...\")\n",
    "    \n",
    "    try:\n",
    "        # BEA API parameters for Regional GDP by County\n",
    "        params = {\n",
    "            'UserID': bea_api_key,\n",
    "            'method': 'GetData',\n",
    "            'datasetname': 'Regional',\n",
    "            'TableName': 'CAGDP9',  # GDP by County, Metro, and Other Areas\n",
    "            'LineCode': '1',  # All industry total\n",
    "            'GeoFips': 'COUNTY',  # All counties\n",
    "            'Year': 'ALL',  # All available years\n",
    "            'ResultFormat': 'JSON'\n",
    "        }\n",
    "        \n",
    "        print(f\"API URL: {BEA_API_URL}\")\n",
    "        print(\"Fetching data (this may take a minute)...\")\n",
    "        \n",
    "        # Make API request\n",
    "        response = requests.get(BEA_API_URL, params=params, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse JSON response\n",
    "        data = response.json()\n",
    "        \n",
    "        # Check for API errors\n",
    "        if 'BEAAPI' in data and 'Error' in data['BEAAPI']:\n",
    "            error_msg = data['BEAAPI']['Error']['ErrorDetail']\n",
    "            print(f\"✗ BEA API Error: {error_msg}\")\n",
    "            return False\n",
    "        \n",
    "        # Extract data from JSON\n",
    "        if 'BEAAPI' in data and 'Results' in data['BEAAPI']:\n",
    "            results = data['BEAAPI']['Results']['Data']\n",
    "            \n",
    "            # Convert to DataFrame\n",
    "            df = pd.DataFrame(results)\n",
    "            \n",
    "            # Save to CSV\n",
    "            df.to_csv(BEA_FILE, index=False)\n",
    "            \n",
    "            print(f\"✓ Data downloaded successfully: {BEA_FILE}\")\n",
    "            print(f\"  File size: {BEA_FILE.stat().st_size / (1024*1024):.2f} MB\")\n",
    "            print(f\"  Records: {len(df):,}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"✗ Unexpected API response format\")\n",
    "            return False\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"✗ Error downloading data: {e}\")\n",
    "        print(\"\\nMake sure you have:\")\n",
    "        print(\"1. Valid BEA API key in your project_api_keys.ipynb\")\n",
    "        print(\"2. Register for a free key at: https://apps.bea.gov/api/signup/\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing data: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0314ba09-1dd8-4663-909e-8e3e6f181c38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load BEA data to dataframe\n",
    "def load_bea_data():\n",
    "    \"\"\"\n",
    "    Load BEA data into a pandas DataFrame\n",
    "    \"\"\"\n",
    "    print(\"\\nLoading BEA data into DataFrame...\")\n",
    "    \n",
    "    try:\n",
    "        # Read CSV into DataFrame\n",
    "        df = pd.read_csv(BEA_FILE, low_memory=False)\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5b8bd78-9af8-4964-8974-07a9836996d1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Execute download\n",
    "download_bea_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01ac9e41-c97d-4bd8-8cef-0ef56ee7687a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load into dataframe\n",
    "bea_df = load_bea_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e388254-35ef-42f4-b29f-cb49f5caebf6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "bea_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "357af03f-1a54-4090-91c0-f30e1803dd10",
   "metadata": {},
   "source": [
    "### Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42bf3c5f-6382-49ba-be5b-3381e955c92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# census ACS API endpoint\n",
    "CENSUS_API_URL = \"https://api.census.gov/data\"\n",
    "CENSUS_FILE = DATA_RAW_DIR / \"census_acs_county.csv\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dadfee4d-2c1e-457c-829f-33cbfed47040",
   "metadata": {},
   "outputs": [],
   "source": [
    "# function to download Census ACS data\n",
    "def download_census_data():\n",
    "    \"\"\"\n",
    "    Download Census American Community Survey (ACS) 5-Year Estimates\n",
    "    Note: Census API does not require authentication for public data\n",
    "    API Documentation: https://www.census.gov/data/developers/data-sets/acs-5year.html\n",
    "    \n",
    "    This downloads key socioeconomic variables at the county level:\n",
    "    - Median household income\n",
    "    - Poverty rate\n",
    "    - Educational attainment\n",
    "    - Unemployment rate\n",
    "    \"\"\"\n",
    "    print(\"Downloading Census ACS data...\")\n",
    "    \n",
    "    try:\n",
    "        # We'll download the most recent 5-year ACS data (2022)\n",
    "        # Key variables for resilience analysis\n",
    "        variables = [\n",
    "            'B19013_001E',  # Median household income\n",
    "            'B17001_002E',  # Population below poverty level\n",
    "            'B17001_001E',  # Total population for poverty calculation\n",
    "            'B23025_005E',  # Unemployed\n",
    "            'B23025_003E',  # In labor force (for unemployment rate)\n",
    "            'B15003_022E',  # Bachelor's degree\n",
    "            'B15003_023E',  # Master's degree\n",
    "            'B15003_024E',  # Professional degree\n",
    "            'B15003_025E',  # Doctorate degree\n",
    "            'B15003_001E',  # Total population 25+ (for education rate)\n",
    "            'B25003_002E',  # Owner occupied housing\n",
    "            'B25003_001E',  # Total occupied housing units\n",
    "            'NAME'          # Geographic name\n",
    "        ]\n",
    "        \n",
    "        year = 2022\n",
    "        dataset = 'acs/acs5'\n",
    "        \n",
    "        params = {\n",
    "            'get': ','.join(variables),\n",
    "            'for': 'county:*',  # All counties\n",
    "            'key': None  # Census API doesn't require key for public data\n",
    "        }\n",
    "        \n",
    "        url = f\"{CENSUS_API_URL}/{year}/{dataset}\"\n",
    "        print(f\"API URL: {url}\")\n",
    "        print(\"Fetching data (this may take a minute)...\")\n",
    "        \n",
    "        # Make API request\n",
    "        response = requests.get(url, params=params, timeout=120)\n",
    "        response.raise_for_status()\n",
    "        \n",
    "        # Parse JSON response\n",
    "        data = response.json()\n",
    "        \n",
    "        # Convert to DataFrame (first row is headers)\n",
    "        df = pd.DataFrame(data[1:], columns=data[0])\n",
    "        \n",
    "        # Save to CSV\n",
    "        df.to_csv(CENSUS_FILE, index=False)\n",
    "        \n",
    "        print(f\"✓ Data downloaded successfully: {CENSUS_FILE}\")\n",
    "        print(f\"  File size: {CENSUS_FILE.stat().st_size / (1024*1024):.2f} MB\")\n",
    "        print(f\"  Records: {len(df):,} counties\")\n",
    "        return True\n",
    "        \n",
    "    except requests.exceptions.RequestException as e:\n",
    "        print(f\"✗ Error downloading data: {e}\")\n",
    "        print(\"\\nNote: Census API is free and doesn't require authentication\")\n",
    "        print(\"Visit: https://www.census.gov/data/developers/data-sets/acs-5year.html\")\n",
    "        return False\n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error processing data: {e}\")\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4a1c86d-8784-4059-88a4-af7101c31752",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load Census data to dataframe\n",
    "def load_census_data():\n",
    "    \"\"\"\n",
    "    Load Census ACS data into a pandas DataFrame\n",
    "    \"\"\"\n",
    "    print(\"\\nLoading Census ACS data into DataFrame...\")\n",
    "    \n",
    "    try:\n",
    "        # Read CSV into DataFrame\n",
    "        df = pd.read_csv(CENSUS_FILE, low_memory=False)\n",
    "        return df\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"✗ Error loading data: {e}\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66e82ae3-4bc0-45be-a25c-d4fb7c584960",
   "metadata": {},
   "outputs": [],
   "source": [
    "# fetch census data download\n",
    "download_census_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd33d3dc-2fd6-42c5-b0da-b53740d601ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# load into dataframe\n",
    "census_df = load_census_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62cfb4aa-aa4b-4d11-bb1b-f2b90b5a02a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "census_df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "332f2c2c-d6d0-4ac6-8a78-e24adecfde8b",
   "metadata": {},
   "source": [
    "## 3. Explore the Data\n",
    "Note: try to get insights from a field expert for these steps.\n",
    " - Create a copy of the data for exploration (sampling it down to a manageable size if necessary).\n",
    " - Create a Jupyter notebook to keep a record of your data exploration.\n",
    " - Study each attribute and its characteristics:\n",
    "    - Name\n",
    "    - Type (categorical, int/float, bounded/unbounded, text, structured, etc.)\n",
    "    - % of missing values\n",
    "    - Noisiness and type of noise (stochastic, outliers, rounding errors, etc.)\n",
    "    - Usefulness for the task\n",
    "    - Type of distribution (Gaussian, uniform, logarithmic, etc.)\n",
    " - For supervised learning tasks, identify the target attribute(s).\n",
    " - Visualize the data.\n",
    " - Study the correlations between attributes.\n",
    " - Study how you would solve the problem manually.\n",
    " - Identify the promising transformations you may want to apply.\n",
    " - Identify extra data that would be useful (go back to “Get the Data” on page 780).\n",
    " - Document what you have learned."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fd60140-d08d-4317-8ab2-79994ee6d104",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### FEMA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "969d3147-e98c-4cbe-84f4-e301a92bac7d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a copy of the FEMA data for exploration\n",
    "fema_explore = fema_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b7de23-c62c-4172-b0ce-cf17b80cead0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dataset info\n",
    "fema_explore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "90176e28-6f2d-4704-8074-664be4f1825c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# statistical summary\n",
    "fema_explore.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "97b4b545-0c04-4b15-9334-9f831d3be948",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check data types and non-null counts\n",
    "fema_explore.dtypes.to_frame(name='dtype')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1da9dc0-dbe7-49f4-a55d-afd09f0aa8ec",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check unique values in key categorical columns\n",
    "fema_explore['incidentType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7078fef-2bbe-49e3-b1af-f1be43d1e55f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# declaration types\n",
    "fema_explore['declarationType'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e97128c0-f618-4400-a497-4b6a600e0efe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the distribution of disasters over time\n",
    "fema_explore['fyDeclared'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d243203-a567-4d00-ae59-f31c053ed294",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify columns relevant for modeling economic resilience\n",
    "# Key columns we need:\n",
    "# - fipsStateCode + fipsCountyCode (to create county FIPS for joining with BEA/Census)\n",
    "# - fyDeclared or declarationDate (temporal - disaster year)\n",
    "# - incidentType (disaster type)\n",
    "# - ihProgramDeclared, iaProgramDeclared, paProgramDeclared, hmProgramDeclared (federal assistance programs)\n",
    "# - disasterNumber (unique disaster identifier)\n",
    "\n",
    "relevant_cols = [\n",
    "    'disasterNumber',\n",
    "    'state', \n",
    "    'fipsStateCode',\n",
    "    'fipsCountyCode',\n",
    "    'declarationType',\n",
    "    'declarationDate',\n",
    "    'fyDeclared',\n",
    "    'incidentType',\n",
    "    'incidentBeginDate',\n",
    "    'ihProgramDeclared',\n",
    "    'iaProgramDeclared', \n",
    "    'paProgramDeclared',\n",
    "    'hmProgramDeclared'\n",
    "]\n",
    "\n",
    "fema_relevant = fema_explore[relevant_cols].copy()\n",
    "fema_relevant.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c4d8959-3b7a-46dd-8da1-66c104313648",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize disaster frequency over time\n",
    "ax = fema_relevant['fyDeclared'].hist(bins=50, figsize=(10, 6))\n",
    "ax.set_xlabel('Fiscal Year Declared')\n",
    "ax.set_ylabel('Number of Disaster Declarations')\n",
    "ax.set_title('FEMA Disaster Declarations Over Time')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e7a1277-62d6-4738-9662-ba97ffe6fa04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize top incident types\n",
    "ax = fema_relevant['incidentType'].value_counts().head(10).plot(kind='barh', figsize=(10, 6))\n",
    "ax.set_xlabel('Number of Declarations')\n",
    "ax.set_ylabel('Incident Type')\n",
    "ax.set_title('Top 10 FEMA Incident Types')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3129911e-5f62-4b5a-a258-cf55a9d60f38",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check distribution of federal assistance programs\n",
    "assistance_programs = fema_relevant[['ihProgramDeclared', 'iaProgramDeclared', \n",
    "                                      'paProgramDeclared', 'hmProgramDeclared']].sum()\n",
    "assistance_programs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4ffbe1c7-f4d9-45be-b264-1b3b6f71a6a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check declaration type distribution\n",
    "fema_relevant['declarationType'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae0ead0d-b75d-4cc2-a507-2c684fd8ff06",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### NOAA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5cbbf208-7b45-4af1-86ab-bf16460766d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of NOAA data for exploration\n",
    "noaa_explore = noaa_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f430057c-b7c6-4a96-bb2a-45391c9daaaf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about NOAA dataset\n",
    "noaa_explore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1da442f8-d7b6-48fa-bba9-52234ca75353",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "noaa_explore.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b28d0464-df80-401d-93bd-6a63bb92e526",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the first few rows to see the structure\n",
    "noaa_explore.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fc06767-f4f1-4d30-b716-96e4ca142ebe",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Check the shape\n",
    "noaa_explore.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8492c60-4167-4f2a-8abe-37700342cd23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the index\n",
    "noaa_explore.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bfd40479-6c8a-4697-9b83-f386824b94c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reload NOAA data with proper header handling\n",
    "noaa_df = pd.read_csv(DATA_RAW_DIR / \"events-US-1980-2021.csv\", \n",
    "                      skiprows=1)  # Skip the title row\n",
    "noaa_explore = noaa_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "671e1aa3-1135-464e-bac4-195971b75fa7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the structure again\n",
    "noaa_explore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "27475ada-98fe-45fd-8aa7-b4c5fd4a41dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "noaa_explore.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "30ad46bf-71b4-429f-880a-589fba92d917",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "noaa_explore.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "223319e0-0816-40ae-b3b9-a590630876d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check disaster types\n",
    "noaa_explore['Disaster'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68a888f5-0e4b-4ce9-874b-8ec31db32ca8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at the temporal range\n",
    "print(f\"Date range: {noaa_explore['Begin Date'].min()} to {noaa_explore['End Date'].max()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cade5d96-6bd1-45a8-ac24-ac7d2fda8868",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize disaster types\n",
    "ax = noaa_explore['Disaster'].value_counts().plot(kind='barh', figsize=(10, 6))\n",
    "ax.set_xlabel('Number of Events')\n",
    "ax.set_ylabel('Disaster Type')\n",
    "ax.set_title('NOAA Billion-Dollar Disasters by Type (1980-2021)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b6485bc-9f65-41cd-b87a-13c06dfdd2c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize cost distribution\n",
    "ax = noaa_explore['Total CPI-Adjusted Cost (Millions of Dollars)'].hist(bins=30, figsize=(10, 6))\n",
    "ax.set_xlabel('Cost (Millions of Dollars)')\n",
    "ax.set_ylabel('Frequency')\n",
    "ax.set_title('Distribution of Billion-Dollar Disaster Costs')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f47dbaec-5c61-4b9f-bde8-1d9d01b394de",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "### BEA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3ea3c6c-4c1c-4d4e-830a-7d1df9193d23",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of BEA data for exploration\n",
    "bea_explore = bea_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49a259c3-68e5-4aa1-aa06-050947a91c8d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about BEA dataset\n",
    "bea_explore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9baea081-50bb-47ac-944f-3877b5dfaa16",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "bea_explore.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e745db1f-21eb-4b09-afdd-4c3ac2d42995",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "bea_explore.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc225d38-2c28-4923-8c3a-bc70ced6e247",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check temporal coverage\n",
    "bea_explore['TimePeriod'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a80c5c3-a58a-461d-96fb-27f726139395",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check number of unique counties\n",
    "print(f\"Number of unique counties: {bea_explore['GeoFips'].nunique()}\")\n",
    "print(f\"Number of years: {bea_explore['TimePeriod'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5364aa99-95c2-4574-aca8-63728e2387b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Look at GDP value distribution\n",
    "ax = bea_explore['DataValue'].hist(bins=50, figsize=(10, 6), log=True)\n",
    "ax.set_xlabel('GDP (Thousands of 2017 Dollars)')\n",
    "ax.set_ylabel('Frequency (log scale)')\n",
    "ax.set_title('Distribution of County GDP Values')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c99646b0-2a3a-485b-a55a-1519ba56f03e",
   "metadata": {},
   "source": [
    "### Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40e33d8e-1a6c-4ef4-a3c4-3e346614acd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a copy of Census data for exploration\n",
    "census_explore = census_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "01415c29-42f9-4e9f-a84d-f896ce6ffce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Basic information about Census dataset\n",
    "census_explore.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae945f2d-da12-4bd0-872a-9448c2749b6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Statistical summary\n",
    "census_explore.describe(include='all')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "87eca805-6d9c-41d7-87ab-814fc3d86f4e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preview the data\n",
    "census_explore.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2fa910e-761b-4ce6-9a3d-b5be0527f3c6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create readable column names for Census variables\n",
    "census_column_map = {\n",
    "    'B19013_001E': 'median_household_income',\n",
    "    'B17001_002E': 'pop_below_poverty',\n",
    "    'B17001_001E': 'total_pop_poverty_status',\n",
    "    'B23025_005E': 'unemployed',\n",
    "    'B23025_003E': 'in_labor_force',\n",
    "    'B15003_022E': 'bachelors_degree',\n",
    "    'B15003_023E': 'masters_degree',\n",
    "    'B15003_024E': 'professional_degree',\n",
    "    'B15003_025E': 'doctorate_degree',\n",
    "    'B15003_001E': 'total_pop_25plus',\n",
    "    'B25003_002E': 'owner_occupied_housing',\n",
    "    'B25003_001E': 'total_occupied_housing',\n",
    "    'NAME': 'county_name',\n",
    "    'state': 'state_fips',\n",
    "    'county': 'county_fips_part'\n",
    "}\n",
    "\n",
    "# Show what each column represents\n",
    "for code, name in census_column_map.items():\n",
    "    print(f\"{code:15} -> {name}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "99a931df-1ba4-4891-a8ce-2120e1b8aa46",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any unusual values (like the negative median income in the summary)\n",
    "census_explore[census_explore['B19013_001E'] < 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00828486-97b0-406b-8250-b1619e98ce5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize median household income distribution (excluding the special code)\n",
    "ax = census_explore[census_explore['B19013_001E'] > 0]['B19013_001E'].hist(bins=50, figsize=(10, 6))\n",
    "ax.set_xlabel('Median Household Income ($)')\n",
    "ax.set_ylabel('Number of Counties')\n",
    "ax.set_title('Distribution of Median Household Income by County (2022)')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "433a14b0-a575-41dc-a58b-ed81680b15a9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate and visualize poverty rate\n",
    "census_explore['poverty_rate'] = (census_explore['B17001_002E'] / census_explore['B17001_001E']) * 100\n",
    "ax = census_explore['poverty_rate'].hist(bins=50, figsize=(10, 6))\n",
    "ax.set_xlabel('Poverty Rate (%)')\n",
    "ax.set_ylabel('Number of Counties')\n",
    "ax.set_title('Distribution of Poverty Rates by County (2022)')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c4a8d80f-5d7b-4676-88f7-34ac758bbea4",
   "metadata": {},
   "source": [
    "### Key Findings from Data Exploration\n",
    "\n",
    "#### FEMA Disaster Declarations (68,509 records)\n",
    "- **Temporal Coverage**: 1953-2026, with significant increase in recent years\n",
    "- **Top Incident Types**: Severe Storm (19,287), Hurricane (13,721), Flood (11,207)\n",
    "- **Declaration Types**: DR (46,006), EM (20,433), FM (2,070)\n",
    "- **Federal Assistance**: PA programs most common (64,026), followed by HM (30,021) and IA (17,187)\n",
    "- **Key Columns for Modeling**: fipsStateCode, fipsCountyCode, fyDeclared, incidentType, assistance programs\n",
    "- **Data Quality**: Missing values in lastIAFilingDate (71.6%), designatedIncidentTypes (69.8%), disasterCloseoutDate (24%)\n",
    "\n",
    "#### NOAA Billion-Dollar Disasters (323 events, 1980-2021)\n",
    "- **Disaster Types**: Severe Storm (152), Tropical Cyclone (57), Flooding (36), Drought (29)\n",
    "- **Cost Range**: $1.0B - $180.0B (CPI-adjusted)\n",
    "- **Limitation**: Multi-state events, needs disaggregation to county level\n",
    "- **Use**: Disaster intensity/severity measure\n",
    "\n",
    "#### BEA Regional GDP (71,714 county-year observations)\n",
    "- **Counties**: 3,118 counties\n",
    "- **Years**: 2001-2023 (23 years, complete panel)\n",
    "- **Key Variable**: DataValue (GDP in thousands of 2017 dollars)\n",
    "- **Use**: Calculate recovery rate (target variable)\n",
    "\n",
    "#### Census ACS 2022 (3,222 counties)\n",
    "- **Socioeconomic Variables**: Income, poverty, unemployment, education, housing\n",
    "- **Data Quality Issue**: Loving County, TX has suppressed values (-666666666)\n",
    "- **Use**: Baseline vulnerability and capacity indicators"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c34acdf-09c2-4f56-afd3-cba6f6131f97",
   "metadata": {},
   "source": [
    "## 4. Prepare the Data\n",
    "Notes:\n",
    " - Work on copies of the data (keep the original dataset intact).\n",
    " - Write functions for all data transformations you apply, for five reasons:\n",
    "    - So you can easily prepare the data the next time you get a fresh dataset\n",
    "    - So you can apply these transformations in future projects\n",
    "    - To clean and prepare the test set\n",
    "    - To clean and prepare new data instances once your solution is live\n",
    "    - To make it easy to treat your preparation choices as hyperparameters\n",
    "1. Clean the data:\n",
    "    - Fix or remove outliers (optional).\n",
    "    - Fill in missing values (e.g., with zero, mean, median…) or drop their rows (or columns).\n",
    "2. Perform feature selection (optional):\n",
    "    - Drop the attributes that provide no useful information for the task.\n",
    "3. Perform feature engineering, where appropriate:\n",
    "    - Discretize continuous features.\n",
    "    - Decompose features (e.g., categorical, date/time, etc.).\n",
    "    - Add promising transformations of features (e.g., log(x), sqrt(x), x2, etc.).\n",
    "    - Aggregate features into promising new features.\n",
    "4. Perform feature scaling:\n",
    "    - Standardize or normalize features."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2de4d8d-8fcb-44dc-a9e1-4c47bbf4859a",
   "metadata": {
    "jp-MarkdownHeadingCollapsed": true
   },
   "source": [
    "#### FEMA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37ef4aea-dc57-4102-9d10-6a737c075f64",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a working copy of FEMA data for prep\n",
    "fema_prep = fema_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0468bc4-0b02-42c1-aeca-879fa495485b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape before prep\n",
    "fema_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00cde57d-28dc-48fb-89f9-69beaea53f6a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-digit county FIPS code (2-digit state + 3-digit county)\n",
    "fema_prep['county_fips'] = (fema_prep['fipsStateCode'].astype(str).str.zfill(2) + \n",
    "                             fema_prep['fipsCountyCode'].astype(str).str.zfill(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd616f39-d1ea-45e1-8ba7-02b771e899c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# verify the result\n",
    "fema_prep[['fipsStateCode', 'fipsCountyCode', 'county_fips']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66bb0fc9-a635-4b7a-b9d6-471f87cb0a4a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date columns to datetime\n",
    "fema_prep['declarationDate'] = pd.to_datetime(fema_prep['declarationDate'])\n",
    "fema_prep['incidentBeginDate'] = pd.to_datetime(fema_prep['incidentBeginDate'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c11b468a-d4a5-4507-969f-54c44ae44a15",
   "metadata": {},
   "outputs": [],
   "source": [
    "# validate the conversion\n",
    "fema_prep[['declarationDate', 'incidentBeginDate', 'fyDeclared']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45803bb9-5335-4009-b4c5-b988df432a58",
   "metadata": {},
   "outputs": [],
   "source": [
    "# select relevant columns for modeling\n",
    "fema_cols = [\n",
    "    'disasterNumber',\n",
    "    'county_fips',\n",
    "    'state',\n",
    "    'declarationType',\n",
    "    'declarationDate',\n",
    "    'fyDeclared',\n",
    "    'incidentType',\n",
    "    'incidentBeginDate',\n",
    "    'ihProgramDeclared',\n",
    "    'iaProgramDeclared',\n",
    "    'paProgramDeclared',\n",
    "    'hmProgramDeclared'\n",
    "]\n",
    "\n",
    "fema_prep = fema_prep[fema_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e0c5f38a-21db-48ce-af06-b1e97b59a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result\n",
    "fema_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a63a3a60-fa41-4e5f-bdc9-8880408681c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check for missing values in prepared FEMA data\n",
    "fema_prep.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a559fb8-8f57-42db-a85d-4a4ad3d06cb8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Aggregate FEMA data to county-year level\n",
    "# Count disasters by type, sum assistance programs\n",
    "fema_county_year = fema_prep.groupby(['county_fips', 'fyDeclared']).agg({\n",
    "    'disasterNumber': 'count',  # Total number of disasters\n",
    "    'ihProgramDeclared': 'sum',\n",
    "    'iaProgramDeclared': 'sum',\n",
    "    'paProgramDeclared': 'sum',\n",
    "    'hmProgramDeclared': 'sum'\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "fema_county_year.columns = ['county_fips', 'year', 'disaster_count', \n",
    "                             'ih_program_total', 'ia_program_total', \n",
    "                             'pa_program_total', 'hm_program_total']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d33f30f3-ddd9-4d95-a6a3-bc7ad66acd2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "fema_county_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2c6eee4-1df1-44e9-b5a6-893e78f8136d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create incident type counts by county-year\n",
    "incident_types = fema_prep.groupby(['county_fips', 'fyDeclared', 'incidentType']).size().reset_index(name='count')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "25e98677-aabd-405e-a480-1609d06889fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pivot to create separate columns for each incident type\n",
    "incident_pivot = incident_types.pivot_table(\n",
    "    index=['county_fips', 'fyDeclared'], \n",
    "    columns='incidentType', \n",
    "    values='count', \n",
    "    fill_value=0\n",
    ").reset_index()\n",
    "\n",
    "# Flatten column names\n",
    "incident_pivot.columns.name = None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb1e63cf-2532-4763-b90d-45c93b1aafbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "incident_pivot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4a5f6cb-34c5-4767-b1ea-5c0ac910bc6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge the aggregated counts with incident types\n",
    "fema_final = fema_county_year.merge(\n",
    "    incident_pivot, \n",
    "    left_on=['county_fips', 'year'], \n",
    "    right_on=['county_fips', 'fyDeclared'],\n",
    "    how='left'\n",
    ").drop(columns=['fyDeclared'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbae1c80-1b00-480d-bed0-64afed01371b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "fema_final.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3abb83f6-d3fa-46e7-b889-183947302558",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape\n",
    "fema_final.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "66ce42af-b4df-4a6f-b554-c7485c9ad19e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prepared FEMA data\n",
    "fema_final.to_csv(DATA_RAW_DIR.parent / \"processed\" / \"fema_prepared.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "256520ef-fb46-4882-982e-a2a64b4f2d0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm save\n",
    "print(f\"FEMA data prepared: {fema_final.shape[0]:,} county-year observations with {fema_final.shape[1]} features\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f805792-8dfb-4226-b88f-0b9a0838754e",
   "metadata": {},
   "source": [
    "#### NOAA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "097de304-c32f-4af8-803e-05fec1ddc1cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# create a working copy of NOAA data for prep\n",
    "noaa_prep = noaa_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d272d8bc-2e2a-4937-bbef-1c4bcd029ebe",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the shape before prep\n",
    "noaa_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17170293-b77d-4f9d-aa3f-03a2346193c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# convert date columns from integer format (YYYYMMDD) to datetime\n",
    "noaa_prep['Begin Date'] = pd.to_datetime(noaa_prep['Begin Date'], format='%Y%m%d')\n",
    "noaa_prep['End Date'] = pd.to_datetime(noaa_prep['End Date'], format='%Y%m%d')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee4f296d-f36c-43fb-8b95-16df1d8133a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract year from Begin Date\n",
    "noaa_prep['year'] = noaa_prep['Begin Date'].dt.year"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75af7c59-a7af-405e-8cf8-c119c5a0fe5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result\n",
    "noaa_prep[['Name', 'Begin Date', 'End Date', 'year']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ed04c745-6d88-4ab4-85cd-a0682fd4c15d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# aggregate NOAA data by year\n",
    "noaa_year = noaa_prep.groupby('year').agg({\n",
    "    'Name': 'count',  # Number of billion-dollar disasters\n",
    "    'Total CPI-Adjusted Cost (Millions of Dollars)': 'sum',  # Total cost\n",
    "    'Deaths': 'sum'  # Total deaths\n",
    "}).reset_index()\n",
    "\n",
    "# Rename columns for clarity\n",
    "noaa_year.columns = ['year', 'billion_dollar_disasters', 'total_disaster_cost_millions', 'total_deaths']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c0d9df8-e61a-497c-a465-1c479ab20cf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# check the result\n",
    "noaa_year.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d12dc01d-a4e9-4ae7-8510-ea784bf82c1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# save prepared NOAA data (national year-level)\n",
    "noaa_year.to_csv(DATA_RAW_DIR.parent / \"processed\" / \"noaa_prepared.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4b97b94-447e-405f-a218-f2a9e376cbcc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# confirm save\n",
    "print(f\"NOAA data prepared: {noaa_year.shape[0]} years with {noaa_year.shape[1]} features\")\n",
    "print(\"Note: NOAA data is at national year-level, not county-level\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb756055-99d1-469e-a833-57115ca37f85",
   "metadata": {},
   "source": [
    "#### BEA Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ae6019be-3625-4d20-81c4-a2118ae52afa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a working copy of BEA data for preparation\n",
    "bea_prep = bea_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bb5c5b40-6983-40da-9a79-53ee98a2d379",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape before preparation\n",
    "bea_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7d0f12ec-3b56-4aa6-a928-348c6629b031",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-digit county FIPS code\n",
    "bea_prep['county_fips'] = bea_prep['GeoFips'].astype(str).str.zfill(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bd56c71b-31b1-4246-96c3-af2ad40e609c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select relevant columns and rename for clarity\n",
    "bea_prep = bea_prep[['county_fips', 'GeoName', 'TimePeriod', 'DataValue']].copy()\n",
    "bea_prep.columns = ['county_fips', 'county_name', 'year', 'gdp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7eb8bf6e-5098-47ba-8288-3b88677c8b94",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "bea_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e500d061-dec0-4779-a975-99dbce30f923",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "bea_prep.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71581b77-1c23-4542-b4f9-d01ac8640ed7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the number of years per county\n",
    "years_per_county = bea_prep.groupby('county_fips')['year'].count()\n",
    "years_per_county.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33f567da-19a2-468e-80f3-4685a2fbe1d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the year range\n",
    "print(f\"Year range: {bea_prep['year'].min()} to {bea_prep['year'].max()}\")\n",
    "print(f\"Number of years: {bea_prep['year'].nunique()}\")\n",
    "print(f\"Number of counties: {bea_prep['county_fips'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65639400-4880-4d04-abe3-ba5d4cf0e488",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Sort by county and year to ensure proper ordering\n",
    "bea_prep = bea_prep.sort_values(['county_fips', 'year']).reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f41dfa3d-9d03-45f4-9251-58fabb2f14dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate GDP 2 years later for each county-year\n",
    "bea_prep['gdp_plus_2'] = bea_prep.groupby('county_fips')['gdp'].shift(-2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f098f314-093a-4c4f-a62b-05b9c712628a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate recovery rate: (GDP_t+2 - GDP_t) / GDP_t\n",
    "bea_prep['recovery_rate'] = (bea_prep['gdp_plus_2'] - bea_prep['gdp']) / bea_prep['gdp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12c480ef-6757-4893-aa1b-fd3be2b1ddc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "bea_prep[['county_fips', 'county_name', 'year', 'gdp', 'gdp_plus_2', 'recovery_rate']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "864bcb8d-0b41-446c-9832-fa6672104298",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values in recovery_rate\n",
    "bea_prep['recovery_rate'].isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "754f790a-76c0-430a-b79a-cba9afac9263",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which years have missing recovery rates\n",
    "bea_prep[bea_prep['recovery_rate'].isnull()]['year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "861bebfa-62fe-4f39-8ff6-9fdea5f8f9cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which counties have missing recovery rates in earlier years\n",
    "early_missing = bea_prep[(bea_prep['recovery_rate'].isnull()) & (bea_prep['year'] < 2022)]\n",
    "early_missing[['county_fips', 'county_name', 'year', 'gdp', 'gdp_plus_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c5d3e31c-a7e7-451c-92a8-ee7bb0575296",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Remove rows where GDP is zero (non-existent counties in those years)\n",
    "bea_prep = bea_prep[bea_prep['gdp'] > 0].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1fab2c9-1e8d-4a43-bd25-548f69267848",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recalculate recovery rate after filtering\n",
    "bea_prep = bea_prep.sort_values(['county_fips', 'year']).reset_index(drop=True)\n",
    "bea_prep['gdp_plus_2'] = bea_prep.groupby('county_fips')['gdp'].shift(-2)\n",
    "bea_prep['recovery_rate'] = (bea_prep['gdp_plus_2'] - bea_prep['gdp']) / bea_prep['gdp']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38d986e5-0ebb-4ae8-88ae-b1864fc2565b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check missing values again\n",
    "print(f\"Total missing recovery rates: {bea_prep['recovery_rate'].isnull().sum()}\")\n",
    "bea_prep[bea_prep['recovery_rate'].isnull()]['year'].value_counts().sort_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e066af6c-15bc-4346-b237-b4e9043a59bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the remaining early missing values\n",
    "early_missing = bea_prep[(bea_prep['recovery_rate'].isnull()) & (bea_prep['year'] < 2022)]\n",
    "early_missing[['county_fips', 'county_name', 'year', 'gdp', 'gdp_plus_2']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "79d6a12a-b00d-4be4-9f87-2522c2e2c8ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prepared BEA data (includes all rows)\n",
    "bea_prep.to_csv(DATA_RAW_DIR.parent / \"processed\" / \"bea_prepared.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20cd24c9-dd4a-446f-847c-6031bec567c7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm save\n",
    "print(f\"BEA data prepared: {bea_prep.shape[0]:,} county-year observations with {bea_prep.shape[1]} features\")\n",
    "print(f\"Observations with valid recovery rates: {bea_prep['recovery_rate'].notna().sum():,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78dd2022-0914-421c-a7cf-5849eaf6c72c",
   "metadata": {},
   "source": [
    "#### Census Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "56fe7310-a37c-4923-9489-4217f457a067",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a working copy of Census data for preparation\n",
    "census_prep = census_df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "081a0b02-1245-44c0-89b7-3163f9571496",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape before preparation\n",
    "census_prep.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "76cf75ab-bbe3-4331-8570-ffdb58d76fc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create 5-digit county FIPS code\n",
    "census_prep['county_fips'] = (census_prep['state'].astype(str).str.zfill(2) + \n",
    "                               census_prep['county'].astype(str).str.zfill(3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07499ca0-58c0-4098-993a-f61a6bc0ac13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename columns to be more readable\n",
    "census_prep = census_prep.rename(columns={\n",
    "    'B19013_001E': 'median_household_income',\n",
    "    'B17001_002E': 'pop_below_poverty',\n",
    "    'B17001_001E': 'total_pop_poverty_status',\n",
    "    'B23025_005E': 'unemployed',\n",
    "    'B23025_003E': 'in_labor_force',\n",
    "    'B15003_022E': 'bachelors_degree',\n",
    "    'B15003_023E': 'masters_degree',\n",
    "    'B15003_024E': 'professional_degree',\n",
    "    'B15003_025E': 'doctorate_degree',\n",
    "    'B15003_001E': 'total_pop_25plus',\n",
    "    'B25003_002E': 'owner_occupied_housing',\n",
    "    'B25003_001E': 'total_occupied_housing',\n",
    "    'NAME': 'county_name'\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "89bfda68-65d9-47cf-ab3e-bb04827f4b92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "census_prep.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "644c92f8-c17f-48f7-9c80-0f6f3feaab07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate derived socioeconomic rates\n",
    "census_prep['poverty_rate'] = (census_prep['pop_below_poverty'] / census_prep['total_pop_poverty_status']) * 100\n",
    "census_prep['unemployment_rate'] = (census_prep['unemployed'] / census_prep['in_labor_force']) * 100\n",
    "census_prep['college_degree_rate'] = ((census_prep['bachelors_degree'] + census_prep['masters_degree'] + \n",
    "                                       census_prep['professional_degree'] + census_prep['doctorate_degree']) / \n",
    "                                      census_prep['total_pop_25plus']) * 100\n",
    "census_prep['homeownership_rate'] = (census_prep['owner_occupied_housing'] / census_prep['total_occupied_housing']) * 100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8142d6e0-277b-41a2-9d4b-e4aca35f2682",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Handle the suppressed value (-666666666) in median_household_income\n",
    "# Replace with NaN for proper handling\n",
    "census_prep['median_household_income'] = census_prep['median_household_income'].replace(-666666666, pd.NA)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05511e66-43e9-4151-ab94-dff06af980e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "census_prep[['county_fips', 'county_name', 'median_household_income', 'poverty_rate', \n",
    "             'unemployment_rate', 'college_degree_rate', 'homeownership_rate']].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cf5b8e1-217b-4fa7-9191-0bf55b027d6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select final columns for modeling\n",
    "census_cols = [\n",
    "    'county_fips',\n",
    "    'county_name',\n",
    "    'median_household_income',\n",
    "    'poverty_rate',\n",
    "    'unemployment_rate',\n",
    "    'college_degree_rate',\n",
    "    'homeownership_rate'\n",
    "]\n",
    "\n",
    "census_prep = census_prep[census_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6fe61b13-59ac-4d9a-94cf-88320614dd6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "census_prep.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e95dc78-756c-4dc0-a393-f675108fad13",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select final columns for modeling\n",
    "census_cols = [\n",
    "    'county_fips',\n",
    "    'county_name',\n",
    "    'median_household_income',\n",
    "    'poverty_rate',\n",
    "    'unemployment_rate',\n",
    "    'college_degree_rate',\n",
    "    'homeownership_rate'\n",
    "]\n",
    "\n",
    "census_prep = census_prep[census_cols].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c6ec5e4-e69f-4ce7-81f2-9fabb50fa283",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for missing values\n",
    "census_prep.isnull().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55e398b7-f1cd-465a-812e-8ef4134c66e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save prepared Census data\n",
    "census_prep.to_csv(DATA_RAW_DIR.parent / \"processed\" / \"census_prepared.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "560bb7b3-68bd-4bc4-a215-48d3d60c3caf",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm save\n",
    "print(f\"Census data prepared: {census_prep.shape[0]:,} counties with {census_prep.shape[1]} features\")\n",
    "print(f\"Missing median_household_income: {census_prep['median_household_income'].isnull().sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "008698e7-1be4-4715-acb1-351d5e82c90a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Start with BEA data (has target variable: recovery_rate)\n",
    "# Only keep rows where we can calculate recovery rate (years 2001-2021)\n",
    "modeling_data = bea_prep[bea_prep['recovery_rate'].notna()].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "813115f1-04d3-4a8a-a247-a3634a8e17e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the shape\n",
    "print(f\"Starting with BEA data: {modeling_data.shape}\")\n",
    "modeling_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f95d6ebc-b17b-4940-88ff-25e7aa66d066",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge FEMA data (county-year level)\n",
    "modeling_data = modeling_data.merge(\n",
    "    fema_final,\n",
    "    on=['county_fips', 'year'],\n",
    "    how='left'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "689c62fd-5c32-47cd-a6ed-e91eb9742f3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "print(f\"After merging FEMA: {modeling_data.shape}\")\n",
    "modeling_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eafba7c8-dd28-44c8-9967-9e0b4979935a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fill NaN values with 0 for counties with no disasters in that year\n",
    "fema_columns = modeling_data.columns[modeling_data.columns.get_loc('disaster_count'):]\n",
    "modeling_data[fema_columns] = modeling_data[fema_columns].fillna(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38a8278e-16d0-44d9-bdeb-5bbbfc20fcfd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "print(f\"Shape after filling FEMA NaNs: {modeling_data.shape}\")\n",
    "modeling_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a83388b-704e-45a7-9971-ef83e97aba9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge Census data (county level - same values for all years)\n",
    "modeling_data = modeling_data.merge(\n",
    "    census_prep,\n",
    "    on='county_fips',\n",
    "    how='left',\n",
    "    suffixes=('', '_census')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93ce4f10-0a57-4efd-a8c9-c5da72c230ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the result\n",
    "print(f\"After merging Census: {modeling_data.shape}\")\n",
    "# Check if there are any counties in BEA that aren't in Census\n",
    "print(f\"Counties with missing Census data: {modeling_data['median_household_income'].isnull().sum()}\")\n",
    "modeling_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f9dd7a2e-cdab-471f-a0a2-bbd6220b7f20",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop the duplicate county_name_census column (keep the original)\n",
    "modeling_data = modeling_data.drop(columns=['county_name_census'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b12318e1-601a-4591-a6bd-096294c90339",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check the final shape and columns\n",
    "print(f\"Final modeling dataset shape: {modeling_data.shape}\")\n",
    "print(f\"\\nColumns: {list(modeling_data.columns)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe168df4-c128-4ffc-834d-54ab2405647a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check for any remaining missing values\n",
    "print(\"\\nMissing values:\")\n",
    "print(modeling_data.isnull().sum()[modeling_data.isnull().sum() > 0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d229e188-e8cd-48ba-99d7-5f5cf52a303c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check which counties are missing Census data\n",
    "missing_census = modeling_data[modeling_data['median_household_income'].isnull()]['county_fips'].unique()\n",
    "print(f\"Number of counties missing Census data: {len(missing_census)}\")\n",
    "print(f\"Sample missing counties:\")\n",
    "modeling_data[modeling_data['county_fips'].isin(missing_census[:5])][['county_fips', 'county_name', 'year']].drop_duplicates('county_fips')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4499ed50-c0be-4069-a278-cf171095c591",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the final merged modeling dataset\n",
    "modeling_data.to_csv(DATA_RAW_DIR.parent / \"processed\" / \"modeling_data.csv\", index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9bfe4c7c-c6da-4370-940b-621def13c083",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final summary\n",
    "print(f\"\\nFinal modeling dataset saved:\")\n",
    "print(f\"  Total observations: {modeling_data.shape[0]:,}\")\n",
    "print(f\"  Features: {modeling_data.shape[1]}\")\n",
    "print(f\"  Counties: {modeling_data['county_fips'].nunique()}\")\n",
    "print(f\"  Years: {modeling_data['year'].min()}-{modeling_data['year'].max()}\")\n",
    "print(f\"  Observations with complete data: {modeling_data.dropna().shape[0]:,}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5efa261-a953-44e7-9651-7690c332bd91",
   "metadata": {},
   "source": [
    "### Data Preparation Summary\n",
    "\n",
    "#### Prepared Datasets\n",
    "\n",
    "**1. FEMA Data** (`fema_prepared.csv`)\n",
    "- 47,646 county-year observations\n",
    "- 34 features: disaster counts, assistance programs, incident type breakdowns\n",
    "- County-year level aggregation\n",
    "\n",
    "**2. NOAA Data** (`noaa_prepared.csv`)\n",
    "- 44 years (1980-2023)\n",
    "- 4 features: billion-dollar disaster counts, total costs, deaths\n",
    "- National year-level (not county-specific)\n",
    "\n",
    "**3. BEA Data** (`bea_prepared.csv`)\n",
    "- 71,587 county-year observations\n",
    "- 6 features including **target variable: recovery_rate**\n",
    "- Recovery rate = (GDP_t+2 - GDP_t) / GDP_t\n",
    "\n",
    "**4. Census Data** (`census_prepared.csv`)\n",
    "- 3,222 counties\n",
    "- 7 features: income, poverty rate, unemployment rate, education, homeownership\n",
    "- 2022 ACS 5-year estimates\n",
    "\n",
    "#### Final Modeling Dataset (`modeling_data.csv`)\n",
    "- **65,351 observations** (county-years from 2001-2021 with valid recovery rates)\n",
    "- **43 features** including:\n",
    "  - Target: recovery_rate\n",
    "  - Economic: gdp, gdp_plus_2\n",
    "  - Disasters: disaster_count, assistance programs, incident types (27 types)\n",
    "  - Socioeconomic: 5 Census-derived rates\n",
    "- **3,118 counties**\n",
    "- **64,624 complete observations** (98.9% completeness)\n",
    "- Missing data: 727 observations missing Census data (county reorganizations)\n",
    "\n",
    "**Next Steps:** Move to Section 5 (Shortlist Promising Models)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e016e529-c33a-42b0-bd96-eeb8a0938911",
   "metadata": {},
   "source": [
    "## 5. Shortlist Promising Models\n",
    "Notes:\n",
    " - If the data is huge, you may want to sample smaller training sets so you can train many different models in a reasonable time (be aware that this penalizes complex models such as large neural nets or random forests).\n",
    " - Once again, try to automate these steps as much as possible.\n",
    "1. Train many quick-and-dirty models from different categories (e.g., linear, naive Bayes, SVM, random forest, neural net, etc.) using standard parameters.\n",
    "2. Measure and compare their performance:\n",
    "    - For each model, use N-fold cross-validation and compute the mean and standard deviation of the performance measure on the N folds.\n",
    "3. Analyze the most significant variables for each algorithm.\n",
    "4. Analyze the types of errors the models make:\n",
    "    - What data would a human have used to avoid these errors?\n",
    "5. Perform a quick round of feature selection and engineering.\n",
    "6. Perform one or two more quick iterations of the five previous steps.\n",
    "7. Shortlist the top three to five most promising models, preferring models that make different types of errors."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5aea22d9-3adb-447e-a9a3-fe33bff8e998",
   "metadata": {},
   "source": [
    "## 6. Fine-Tune the System\n",
    "Notes:\n",
    " - You will want to use as much data as possible for this step, especially as you move toward the end of fine-tuning.\n",
    " - As always, automate what you can.\n",
    "1. Fine-tune the hyperparameters using cross-validation:\n",
    "    - Treat your data transformation choices as hyperparameters, especially when you are not sure about them (e.g., if you’re not sure whether to replace missing values with zeros or with the median value, or to just drop the rows).\n",
    "    - Unless there are very few hyperparameter values to explore, prefer random search over grid search. If training is very long, you may prefer a Bayesian optimization approach (e.g., using Gaussian process priors, as described by Jasper Snoek et al.1).\n",
    "2. Try ensemble methods. Combining your best models will often produce better performance than running them individually.\n",
    "3. Once you are confident about your final model, measure its performance on the test set to estimate the generalization error."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8860e43-93d6-4c87-bda3-ee6b2f5d0a6a",
   "metadata": {},
   "source": [
    "## 7. Present your Solution\n",
    "1. Document what you have done.\n",
    "2. Create a nice presentation:\n",
    "    - Make sure you highlight the big picture first.\n",
    "3. Explain why your solution achieves the business objective.\n",
    "4. Don’t forget to present interesting points you noticed along the way:\n",
    "    - Describe what worked and what did not.\n",
    "    - List your assumptions and your system’s limitations.\n",
    "5. Ensure your key findings are communicated through beautiful visualizations or easy-to-remember statements (e.g., “the median income is the number-one predictor of housing prices”)."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9235995-251c-4c2e-91c5-8bbd9b97b627",
   "metadata": {},
   "source": [
    "## 8. Launch!\n",
    "1. Get your solution ready for production (plug into production data inputs, write unit tests, etc.).\n",
    "2. Write monitoring code to check your system’s live performance at regular intervals and trigger alerts when it drops:\n",
    "    - Beware of slow degradation: models tend to “rot” as data evolves.\n",
    "    - Measuring performance may require a human pipeline (e.g., via a crowdsourcing service).\n",
    "    - Also monitor your inputs’ quality (e.g., a malfunctioning sensor sending random values, or another team’s output becoming stale). This is particularly important for online learning systems.\n",
    "3. Retrain your models on a regular basis on fresh data (automate as much as possible)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e751ed45-81ab-43f2-adc1-b17534672e52",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
